# CPU cache

## 为什么需要高速缓存

- 这里的高速缓存指的是实实在在的SRAM；
- CPU速度与内存(DRAM)访问速度差距越来越大，现在两者已有120倍差距；
- 为了减少CPU傻等内存的情况，引入高速缓存；
- 95%情况下，CPU都可以从L1-L3 cache拿到指令和数据，而不是内存；

![image](https://github.com/ingangi/blog/blob/master/img/cpu_cache_l.jpeg)

> L1/L2的大小基本上也就是KB级别的，L3会是MB级别的。例如：Intel Core i7-8700K ，是一个6核的CPU，每核上的L1是64KB（数据和指令各32KB），L2 是 256K，L3有12MB

### Cache Line

- CPU从内存读数据到cache过程中，是以缓存块(cache line)为粒度的。
- 在intel服务器或PC中，cache line通常是64Byte.
```
// index0-3分别对应：L1数据cache，L1指令cache，L2cache，L3cache
// 查看cache line大小
cat /sys/devices/system/cpu/cpu1/cache/index0/coherency_line_size
// 查看cache大小
cat /sys/devices/system/cpu/cpu1/cache/index0/size
```

## 怎么使用Cache

- 无论数据是否在cache里，CPU都先访问cache；
- 若发现cache中没有，才会访问内存，并读到cache里；

### 直接映射Cache

将内存地址映射到cache地址，通常是通过mod运算！

> 技巧：将缓存块数量设置为2的N次方，则对内存地址求余过程可以简化为取内存地址2进制表示的低N位！（比如缓存块有2^3=8块，则内存地址21对应的缓存块是b'101'=5。）

![image](https://github.com/ingangi/blog/blob/master/img/cpu_cache_dir_map.png)

#### 缓存块中有什么？

1. 组标记（tag）：记录当前缓存块对应的内存块地址的高M-N位；
2. 有效位（valid bit）：数据是否有效；
3. 数据；

#### 读取流程

1. 根据内存地址低N位，计算在cache中的索引；
2. 判断有效位；
3. 对比内存地址高位和组标记，判断是否是想要的内存地址的数据，得到data block；
4. 根据offset从data block中读到想要的字。

![image](https://github.com/ingangi/blog/blob/master/img/cpu_cache_dir_map_read.png)

## 怎么更新数据

### volatile关键字

> A volatile specifier is a hint to a compiler that an object may change its value in ways not specified by the language so that aggressive optimizations must be avoided.

被volatile修饰的变量，可能被代码以为的因素改变，提醒编译器不应优化对它的读取，应总是从内存重新读取它，而不是Cpu Cache/寄存器。

### 写直达(write-through)

总是会把数据写入内存（因此比较慢），写入内存前会判断下是否存在缓存，若有缓存则更新缓存的数据。

![image](https://github.com/ingangi/blog/blob/master/img/cpu_cache_write_through.jpeg)

### 写回(write-back)

只写缓存，将写内存动作延后。

1. 写前判断是否已在缓存；
2. 如果已在缓存中，则更新缓存数据，同时标记缓存为脏(需要同步内存)，结束；
3. 如果不在缓存，则判断对应地址的缓存(其它内存的数据)是否脏；
4. 如果脏，则将那个缓存的数据写回内存，把本次数据写入缓存；
5. 执行步骤2；

![image](https://github.com/ingangi/blog/blob/master/img/cpu_cache_write_back.jpeg)

## 代码优化

### false sharing伪共享问题

![image](https://github.com/ingangi/blog/blob/master/img/false_sharing.png)

上图中，一个运行在处理器 core1上的线程想要更新变量 X 的值，同时另外一个运行在处理器 core2 上的线程想要更新变量Y的值。但是，这两个频繁改动的变量都处于同一条缓存行。两个线程就会轮番发送 RFO 消息，占得此缓存行的拥有权。当 core1 取得了拥有权开始更新 X，则 core2 对应的缓存行需要设为 I 状态。当 core2 取得了拥有权开始更新 Y，则 core1 对应的缓存行需要设为 I 状态(失效态)。轮番夺取拥有权不但带来大量的 RFO 消息，而且如果某个线程需要读此行数据时，L1 和 L2 缓存上都是失效数据，只有 L3 缓存上是同步好的数据。从前一篇我们知道，读 L3 的数据非常影响性能。更坏的情况是跨槽读取，L3 都要 miss，只能从内存上加载。

表面上 X 和 Y 都是被独立线程操作的，而且两操作之间也没有任何关系。只不过它们共享了一个缓存行，但所有竞争冲突都是来源于共享。

### 思路：让不同线程操作的对象处于不同的缓存行

```
// Determine the cache line size for the host CPU.
//为各种CPU定义告诉缓存行大小
#define CACHE_ALIGN  64
 
#define CACHE_PAD(Name, BytesSoFar) \
   BYTE Name[CACHE_ALIGN - ((BytesSoFar) % CACHE_ALIGN)]
 
struct CUSTINFO
{
   DWORD    dwCustomerID;     // Mostly read-only
   char     szName[100];      // Mostly read-only
 
   //Force the following members to be in a different cache line.
   //这句很关键用一个算出来的Byte来填充空闲的告诉缓存行
   //如果指定了告诉缓存行的大小可以简写成这样
   //假设sizeof(DWORD) + 100 = 108；告诉缓存行大小为32
   //BYTE[12]；
   //作用呢就是强制下面的数据内容与上面数据内容不在同一高速缓存行中。
   CACHE_PAD(bPad1, sizeof(DWORD) + 100);
 
   int      nBalanceDue;      // Read-write
   FILETIME ftLastOrderDate;  // Read-write
 
   //Force the following structure to be in a different cache line.
   CACHE_PAD(bPad2, sizeof(int) + sizeof(FILETIME));
};
```