# GPU

## 图形流水线（Graphic Pipeline）

基于多边形建模的三位图像实时渲染的计算过程。

> 这个过程计算量很大（需要渲染整个画面里的每个像素），CPU扛不住，也不需要CPU这么复杂的架构。

### 1. 顶点处理

将**多边形的顶点**在三维空间中的坐标转换到屏幕的二维空间。

### 2. 图元处理

将二维化的顶点连接起来，形成多边形，并且剔除不在屏幕里的内容。

### 3. 栅格化

将图元处理后的多边形转换成像素点阵。

### 4. 片段处理

给像素点上色：计算每个像素的颜色、透明度。

### 5. 像素操作

将有重叠的多边形像素点合并。

![image](https://github.com/ingangi/blog/blob/master/img/gpu_pipeline.jpeg)

## GPU为什么比CPU更擅长并行计算？

GPU相比CPU结构更简单：

![image](https://github.com/ingangi/blog/blob/master/img/gpu_cpu_diff.jpeg)

### SIMT技术

借鉴CPU的SIMD（并行计算多个数据），SIMT可以把多条数据交给不同线程处理。

![image](https://github.com/ingangi/blog/blob/master/img/gpu_simt.jpeg)

### 超线程

因为GPU中没有分支预测电路，因此不可避免流水线停顿，为了高效利用停顿时间的GPU，可以借鉴CPU的**超线程**技术，调度别的任务给ALU。通过增加寄存器来提供更多执行上下文，达到超线程的目的：

![image](https://github.com/ingangi/blog/blob/master/img/gpu_thread.jpeg)

### 深度学习上的应用

深度学习计算以超大向量和矩阵、海量训练样本计算等为主，没有复杂的逻辑分支，适合GPU计算。相比CPU，能缩短一两个数量级！
