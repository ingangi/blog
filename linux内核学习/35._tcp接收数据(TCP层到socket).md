# tcp接收数据(TCP层到socket)

## TCP层：数据入队列

### tcp_v4_rcv()

```
// 注意  此时还在软中断处理过程中，因此这个函数不可占用太久时间
// 因此需要队列来暂存数据 对此后的流程进行解耦，不会在这里等待
int tcp_v4_rcv(struct sk_buff *skb)
{
	struct net *net = dev_net(skb->dev);
	const struct iphdr *iph;
	const struct tcphdr *th;
	bool refcounted;
	struct sock *sk;  //状态维护在sock里
	int ret;
......
	th = (const struct tcphdr *)skb->data;  //TCP header
	iph = ip_hdr(skb);
......
    // 拷贝TCP头相关字段
	TCP_SKB_CB(skb)->seq = ntohl(th->seq);
	TCP_SKB_CB(skb)->end_seq = (TCP_SKB_CB(skb)->seq + th->syn + th->fin + skb->len - th->doff * 4);
	TCP_SKB_CB(skb)->ack_seq = ntohl(th->ack_seq);
	TCP_SKB_CB(skb)->tcp_flags = tcp_flag_byte(th);
	TCP_SKB_CB(skb)->tcp_tw_isn = 0;
	TCP_SKB_CB(skb)->ip_dsfield = ipv4_get_dsfield(iph);
	TCP_SKB_CB(skb)->sacked	 = 0;

lookup:
	sk = __inet_lookup_skb(&tcp_hashinfo, skb, __tcp_hdrlen(th), th->source, th->dest, &refcounted);  //找到sock，从而可以获取到TCP状态

process:
	if (sk->sk_state == TCP_TIME_WAIT)
		goto do_time_wait;

	if (sk->sk_state == TCP_NEW_SYN_RECV) {
......
	}
......
	th = (const struct tcphdr *)skb->data;
	iph = ip_hdr(skb);

	skb->dev = NULL;

	if (sk->sk_state == TCP_LISTEN) {
		ret = tcp_v4_do_rcv(sk, skb);
		goto put_and_return;
	}
......
	if (!sock_owned_by_user(sk)) {  //是否有用户态进程等待读取？
	
		if (!tcp_prequeue(sk, skb)) //尝试放入prequeue队列，放成功了马上走则会获得更高的吞吐，但数据延时会变高
			ret = tcp_v4_do_rcv(sk, skb); //没放成功，马上处理则获得了更低的延时，但牺牲了吞吐量！
			
	} else if (tcp_add_backlog(sk, skb)) { //没人要或者用户正在忙处理其它队列的数据时 加到backlog队列! 闪人，不等人要了!
		goto discard_and_relse;
	}
......
}

```

### 三个队列

- backlog队列：没人要或者用户正在忙处理其它队列的数据时，新来的数据暂存在这里。
- prequeue队列：依赖net.ipv4.tcp_low_latency的设置。

#### ipv4.tcp_low_latency

> net.ipv4.tcp_low_latency 为0时，策略倾向高吞吐量（数据先进入prequeue队列），为1时倾向数据接收的低延时。

- sk_receive_queue队列：已处理的（掐头去尾了）、排好序的数据，给用户使用。

### tcp_v4_do_rcv() (乱序处理)

```
// tcp_v4_do_rcv()中针对ESTABLISHED状态的数据**入队列**处理：
static void tcp_data_queue(struct sock *sk, struct sk_buff *skb)
{
	struct tcp_sock *tp = tcp_sk(sk);
	bool fragstolen = false;
......
    // 1. 来包的序号 正是我们期望的！
	if (TCP_SKB_CB(skb)->seq == tp->rcv_nxt) {
		if (tcp_receive_window(tp) == 0)
			goto out_of_window;

		/* Ok. In sequence. In window. */
		if (tp->ucopy.task == current &&
		    tp->copied_seq == tp->rcv_nxt && tp->ucopy.len &&
		    sock_owned_by_user(sk) && !tp->urg_data) { //用户正在等待读取 FAST PATH!
			int chunk = min_t(unsigned int, skb->len,
					  tp->ucopy.len);

			__set_current_state(TASK_RUNNING);

            //  直接将数据拷贝给用户进程！
			if (!skb_copy_datagram_msg(skb, 0, tp->ucopy.msg, chunk)) {
				tp->ucopy.len -= chunk;
				tp->copied_seq += chunk;
				eaten = (chunk == skb->len);
				tcp_rcv_space_adjust(sk);
			}
		}

		if (eaten <= 0) {
queue_and_out:
......
			eaten = tcp_queue_rcv(sk, skb, 0, &fragstolen); //用户暂时没空，放到 sk_receive_queue。
		}
		// 更新下一个期待的序号
		tcp_rcv_nxt_update(tp, TCP_SKB_CB(skb)->end_seq);
......
        // 看看这个包的到来会不会挽救一些在乱序队列中等待的包
		if (!RB_EMPTY_ROOT(&tp->out_of_order_queue)) {
			tcp_ofo_queue(sk);
......
		}
......
		return;
	}

    // 来包end_seq序号小于期待
	if (!after(TCP_SKB_CB(skb)->end_seq, tp->rcv_nxt)) {
		/* A retransmit, 2nd most common case.  Force an immediate ack. */
		// 马上回复ACK，让对方知道已收到，别发了（对方可能在重传）
		tcp_dsack_set(sk, TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq);

out_of_window:
		tcp_enter_quickack_mode(sk);
		inet_csk_schedule_ack(sk);
drop:
		tcp_drop(sk, skb);
		return;
	}

	/* Out of window. F.e. zero window probe. */
	// 超出接收窗口！ 对方发的太猛
	if (!before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt + tcp_receive_window(tp)))
		goto out_of_window;

	tcp_enter_quickack_mode(sk);

    // seq < rcv_nxt < end_seq：有部分重复数据
	if (before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt)) {
		/* Partial packet, seq < rcv_next < end_seq */
		tcp_dsack_set(sk, TCP_SKB_CB(skb)->seq, tp->rcv_nxt);
		/* If window is closed, drop tail of packet. But after
		 * remembering D-SACK for its head made in previous line.
		 */
		if (!tcp_receive_window(tp))
			goto out_of_window;
		goto queue_and_out;
	}

    // 其它情况：一定是个乱序包！
	tcp_data_queue_ofo(sk, skb);
}

```

## socket层：数据出队列

### tcp_recvmsg()

从文件系统开始层层调用到tcp_recvmsg()

```
int tcp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len, int nonblock,
		int flags, int *addr_len)
{
	struct tcp_sock *tp = tcp_sk(sk);
	int copied = 0;
	u32 peek_seq;
	u32 *seq;
	unsigned long used;
	int err;
	int target;		/* Read at least this many bytes */
	long timeo;
	struct task_struct *user_recv = NULL;
	struct sk_buff *skb, *last;
.....
	do {
		u32 offset;
......
		/* Next get a buffer. */
		// 1. 优先处理sk_receive_queue队列！
		last = skb_peek_tail(&sk->sk_receive_queue);
		skb_queue_walk(&sk->sk_receive_queue, skb) {
			last = skb;
			offset = *seq - TCP_SKB_CB(skb)->seq;
			if (offset < skb->len)
				goto found_ok_skb; //拷贝到用户进程
......
		}
......
        // 2. 判断latency，是否处理prequeue队列
		if (!sysctl_tcp_low_latency && tp->ucopy.task == user_recv) {
			/* Install new reader */
			if (!user_recv && !(flags & (MSG_TRUNC | MSG_PEEK))) {
				user_recv = current;
				tp->ucopy.task = user_recv;
				tp->ucopy.msg = msg;
			}

			tp->ucopy.len = len;
			/* Look: we have the following (pseudo)queues:
			 *
			 * 1. packets in flight
			 * 2. backlog
			 * 3. prequeue
			 * 4. receive_queue
			 *
			 * Each queue can be processed only if the next ones
			 * are empty. 
			 */
			if (!skb_queue_empty(&tp->ucopy.prequeue))
				goto do_prequeue;
		}

		if (copied >= target) {
			/* Do not sleep, just process backlog. */
			// 3. 最后处理backlog队列
			release_sock(sk);  
			lock_sock(sk);
		} else {
		    // 4. 所有队列都没事干，继续等待
			sk_wait_data(sk, &timeo, last);
		}
......
	} while (len > 0);
......
}

```

## 完整调用链

![image](https://github.com/ingangi/blog/blob/master/img/socket_tcp_rcv.png)
